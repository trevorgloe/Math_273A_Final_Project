{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import monomial_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating an nn with 4 hidden layers\n",
      "ShallowNeuralNetwork(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (output): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (quad): polynomial()\n",
      ")\n",
      "starting training\n",
      "Epoch [0/10000], Loss: 57.22518\n",
      "Epoch [200/10000], Loss: 35.39485\n",
      "Epoch [400/10000], Loss: 7.68414\n",
      "Epoch [600/10000], Loss: 0.38713\n",
      "Epoch [800/10000], Loss: 0.04718\n",
      "Epoch [1000/10000], Loss: 0.01145\n",
      "Epoch [1200/10000], Loss: 0.00447\n",
      "Epoch [1400/10000], Loss: 0.00314\n",
      "Epoch [1600/10000], Loss: 0.00253\n",
      "Epoch [1800/10000], Loss: 0.00209\n",
      "Epoch [2000/10000], Loss: 0.00176\n",
      "Epoch [2200/10000], Loss: 0.00151\n",
      "Epoch [2400/10000], Loss: 0.00132\n",
      "Epoch [2600/10000], Loss: 0.00118\n",
      "Epoch [2800/10000], Loss: 0.00107\n",
      "Epoch [3000/10000], Loss: 0.00099\n",
      "Epoch [3200/10000], Loss: 0.00092\n",
      "Epoch [3400/10000], Loss: 0.00086\n",
      "Epoch [3600/10000], Loss: 0.00081\n",
      "Epoch [3800/10000], Loss: 0.00076\n",
      "Epoch [4000/10000], Loss: 0.00072\n",
      "Epoch [4200/10000], Loss: 0.00068\n",
      "Epoch [4400/10000], Loss: 0.00064\n",
      "Epoch [4600/10000], Loss: 0.00061\n",
      "Epoch [4800/10000], Loss: 0.00058\n",
      "Epoch [5000/10000], Loss: 0.00055\n",
      "Epoch [5200/10000], Loss: 0.00053\n",
      "Epoch [5400/10000], Loss: 0.00050\n",
      "Epoch [5600/10000], Loss: 0.00048\n",
      "Epoch [5800/10000], Loss: 0.00045\n",
      "Epoch [6000/10000], Loss: 0.00043\n",
      "Epoch [6200/10000], Loss: 0.00041\n",
      "Epoch [6400/10000], Loss: 0.00040\n",
      "Epoch [6600/10000], Loss: 0.00038\n",
      "Epoch [6800/10000], Loss: 0.00036\n",
      "Epoch [7000/10000], Loss: 0.00035\n",
      "Epoch [7200/10000], Loss: 0.00033\n",
      "Epoch [7400/10000], Loss: 0.00032\n",
      "Epoch [7600/10000], Loss: 0.00031\n",
      "Epoch [7800/10000], Loss: 0.00029\n",
      "Epoch [8000/10000], Loss: 0.00028\n",
      "Epoch [8200/10000], Loss: 0.00027\n",
      "Epoch [8400/10000], Loss: 0.00026\n",
      "Epoch [8600/10000], Loss: 0.00025\n",
      "Epoch [8800/10000], Loss: 0.00024\n",
      "Epoch [9000/10000], Loss: 0.00023\n",
      "Epoch [9200/10000], Loss: 0.00022\n",
      "Epoch [9400/10000], Loss: 0.00021\n",
      "Epoch [9600/10000], Loss: 0.00021\n",
      "Epoch [9800/10000], Loss: 0.00020\n",
      "\n",
      "Training Complete\n",
      "ShallowNeuralNetwork(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (output): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (quad): polynomial()\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.8426, -0.7893],\n",
      "        [-0.3015, -0.1840],\n",
      "        [ 0.3079, -1.7929],\n",
      "        [ 0.8673, -0.2833]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0766,  0.3101, -0.8249,  0.3136], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.5827, -0.3695,  1.3549,  0.4397]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "teacher_W = np.array([[1,2, 0.4],[1,-1, -0.2],[0,2, 0.9], [1,1, 0]])\n",
    "teacher_v = np.array([[0, 1, 1, -0.2]])\n",
    "dim_x = 2\n",
    "dim_y = 1\n",
    "N = 10\n",
    "\n",
    "outmodel = monomial_activations.student_teacher_train(teacher_W=teacher_W, teacher_v=teacher_v, dim_x=dim_x, dim_y=dim_y, N=N, num_epochs=10000, lr=5e-3)\n",
    "print(outmodel)\n",
    "print(outmodel.hidden.weight)\n",
    "print(outmodel.hidden.bias)\n",
    "print(outmodel.output.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim_F2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

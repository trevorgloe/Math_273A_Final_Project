{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import monomial_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating an nn with 4 hidden layers\n",
      "ShallowNeuralNetwork(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (output): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (quad): polynomial()\n",
      ")\n",
      "starting training\n",
      "Epoch [0/10000], Loss: 1232.86365\n",
      "Epoch [200/10000], Loss: 225.21255\n",
      "Epoch [400/10000], Loss: 9.92343\n",
      "Epoch [600/10000], Loss: 0.38061\n",
      "Epoch [800/10000], Loss: 0.15241\n",
      "Epoch [1000/10000], Loss: 0.07299\n",
      "Epoch [1200/10000], Loss: 0.04617\n",
      "Epoch [1400/10000], Loss: 0.03729\n",
      "Epoch [1600/10000], Loss: 0.03437\n",
      "Epoch [1800/10000], Loss: 0.03337\n",
      "Epoch [2000/10000], Loss: 0.03299\n",
      "Epoch [2200/10000], Loss: 0.03289\n",
      "Epoch [2400/10000], Loss: 0.03285\n",
      "Epoch [2600/10000], Loss: 0.03279\n",
      "Epoch [2800/10000], Loss: 0.03273\n",
      "Epoch [3000/10000], Loss: 0.03269\n",
      "Epoch [3200/10000], Loss: 0.03264\n",
      "Epoch [3400/10000], Loss: 0.03257\n",
      "Epoch [3600/10000], Loss: 0.03252\n",
      "Epoch [3800/10000], Loss: 0.03246\n",
      "Epoch [4000/10000], Loss: 0.03242\n",
      "Epoch [4200/10000], Loss: 0.03236\n",
      "Epoch [4400/10000], Loss: 0.03229\n",
      "Epoch [4600/10000], Loss: 0.03221\n",
      "Epoch [4800/10000], Loss: 0.03215\n",
      "Epoch [5000/10000], Loss: 0.03209\n",
      "Epoch [5200/10000], Loss: 0.03203\n",
      "Epoch [5400/10000], Loss: 0.03197\n",
      "Epoch [5600/10000], Loss: 0.03191\n",
      "Epoch [5800/10000], Loss: 0.03184\n",
      "Epoch [6000/10000], Loss: 0.03175\n",
      "Epoch [6200/10000], Loss: 0.03167\n",
      "Epoch [6400/10000], Loss: 0.03157\n",
      "Epoch [6600/10000], Loss: 0.03148\n",
      "Epoch [6800/10000], Loss: 0.03141\n",
      "Epoch [7000/10000], Loss: 0.03132\n",
      "Epoch [7200/10000], Loss: 0.03124\n",
      "Epoch [7400/10000], Loss: 0.03115\n",
      "Epoch [7600/10000], Loss: 0.03105\n",
      "Epoch [7800/10000], Loss: 0.03094\n",
      "Epoch [8000/10000], Loss: 0.03083\n",
      "Epoch [8200/10000], Loss: 0.03073\n",
      "Epoch [8400/10000], Loss: 0.03062\n",
      "Epoch [8600/10000], Loss: 0.03051\n",
      "Epoch [8800/10000], Loss: 0.03039\n",
      "Epoch [9000/10000], Loss: 0.03027\n",
      "Epoch [9200/10000], Loss: 0.03015\n",
      "Epoch [9400/10000], Loss: 0.03001\n",
      "Epoch [9600/10000], Loss: 0.02987\n",
      "Epoch [9800/10000], Loss: 0.02973\n",
      "\n",
      "Training Complete\n",
      "ShallowNeuralNetwork(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (output): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (quad): polynomial()\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 7.2764e-02, -2.2852e-04],\n",
      "        [ 4.9074e-01, -1.8664e+00],\n",
      "        [ 3.8442e-01,  5.8087e-01],\n",
      "        [-9.3542e-01,  2.1560e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2504, -0.7642,  0.5655, -0.4167], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3285,  1.3279,  0.4754,  0.4646]], requires_grad=True)\n",
      "Difference in W^T W\n",
      "[[-1.73108304 -2.89433384  0.01399367]\n",
      " [-2.89433384 -6.13248658 -1.13499861]\n",
      " [ 0.01399367 -1.13499861  0.13016056]]\n"
     ]
    }
   ],
   "source": [
    "teacher_W = np.array([[1,2, 0.4],[1,-1, -0.2],[0,2, 0.9], [1,1, 0]])\n",
    "teacher_v = np.array([[0, 1, 1, -0.2]])\n",
    "dim_x = 2\n",
    "dim_y = 1\n",
    "N = 20\n",
    "\n",
    "outmodel = monomial_activations.student_teacher_train(teacher_W=teacher_W, teacher_v=teacher_v, dim_x=dim_x, dim_y=dim_y, N=N, num_epochs=10000, lr=3e-3)\n",
    "print(outmodel)\n",
    "print(outmodel.hidden.weight)\n",
    "print(outmodel.hidden.bias)\n",
    "print(outmodel.output.weight)\n",
    "student_w_unbias = outmodel.hidden.weight.detach().numpy()\n",
    "student_w_bias = outmodel.hidden.bias.detach().numpy()\n",
    "student_w_bias = np.array([student_w_bias]).T\n",
    "# print(student_w_unbias)\n",
    "# print(student_w_bias)\n",
    "student_w = np.hstack((student_w_unbias, student_w_bias))\n",
    "print(\"Difference in W^T W\")\n",
    "print(student_w.T @ student_w - teacher_W.T @ teacher_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim_F2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
